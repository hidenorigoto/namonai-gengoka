# 音声思考支援アプリケーション アーキテクチャドキュメント

## 1. プロジェクト概要

### 1.1 目的
ユーザーの思考の言語化を支援するWebベースのアプリケーション。音声入力を通じてアイデアを話し、AIが内容を解析・構造化して概念マップとして可視化する。

### 1.2 主要機能
- リアルタイム音声認識（日本語）
- AI による概念抽出・構造化
- インタラクティブな概念ツリー表示
- 選択概念に対する深掘り質問生成

### 1.3 PoC スコープ
- データ永続化なし（ブラウザセッション内完結）
- シングルユーザー
- 最小限のUI実装

## 2. システムアーキテクチャ

### 2.1 全体構成
```
┌─────────────────────────────────────────┐
│         ブラウザ (Client)                │
│                                         │
│  ┌─────────────┐  ┌─────────────────┐  │
│  │   React     │  │  Web Speech API │  │
│  │   App       │  │                 │  │
│  └──────┬──────┘  └────────┬────────┘  │
│         │                   │           │
│         └─────────┬─────────┘           │
│                   │                     │
│           ┌───────▼────────┐            │
│           │  OpenAI API    │            │
│           │  (Direct Call) │            │
│           └────────────────┘            │
└─────────────────────────────────────────┘
```

### 2.2 技術スタック
- **フロントエンド**: React + TypeScript
- **音声認識**: Web Speech API
- **AI処理**: OpenAI API (GPT-3.5/4)
- **状態管理**: React State + Context API
- **スタイリング**: CSS Modules

## 3. コンポーネント設計

### 3.1 コンポーネント構成
```
src/
├── App.tsx                 # メインアプリケーション
├── components/
│   ├── VoiceInput.tsx     # 音声入力制御
│   ├── ConceptTree.tsx    # 概念ツリー表示
│   ├── ConceptDetail.tsx  # 概念詳細パネル
│   └── ApiKeyModal.tsx    # APIキー設定
├── services/
│   ├── speechRecognition.ts
│   ├── openaiService.ts
│   └── apiKeyManager.ts
└── types/
    └── index.ts           # 型定義
```

### 3.2 主要コンポーネントの責務

#### VoiceInput
- 音声認識の開始/停止制御
- 認識結果のテキスト化
- 録音状態の表示

#### ConceptTree
- 概念の階層表示（インデントテキスト形式）
- クリックによる概念選択
- 選択状態のハイライト表示

#### ConceptDetail
- 選択された概念の詳細表示
- AI生成質問の表示
- 質問への回答入力（将来拡張）

## 4. データフロー

### 4.1 音声入力から概念表示まで
```
1. ユーザーが録音開始ボタンを押下
2. Web Speech API で音声を連続認識
3. 確定したテキストをバッファに蓄積
4. 10秒ごとに OpenAI API で概念抽出
5. 抽出結果を概念ツリーとして表示
6. ユーザーが概念をクリック
7. 選択概念に対する質問を生成・表示
```

### 4.2 状態管理
```typescript
interface AppState {
  // 音声認識
  isRecording: boolean;
  transcribedText: string;
  
  // 概念構造
  concepts: ConceptNode[];
  selectedConceptIds: Set<string>;
  
  // UI状態
  isProcessing: boolean;
  apiKey: string | null;
}

interface ConceptNode {
  id: string;
  text: string;
  level: number;
  children: ConceptNode[];
}
```

## 5. UI/UX デザイン

### 5.1 レイアウト
```
┌─────────────────────────────────────────────────────┐
│  🎤 録音中... | ⚙️設定                              │
├────────────────────────┬────────────────────────────┤
│                        │                            │
│   概念ツリー (40%)      │   詳細パネル (60%)         │
│                        │                            │
│ ▼ 思考の言語化          │  【選択中の概念】           │
│   ▼ 音声認識 ●         │  リアルタイム音声認識        │
│     • Web Speech API   │                            │
│     • 日本語処理       │  📝 詳細説明:               │
│   ▶ AI解析            │  Web Speech APIを使用して   │
│                        │  ブラウザ上で音声を...      │
│                        │                            │
│ [録音開始/停止]        │  💭 AI生成の質問:           │
│                        │  1. 認識精度の目標は？       │
│                        │  2. エラー時の対処は？       │
└────────────────────────┴────────────────────────────┘
```

### 5.2 インタラクション
- **クリック**: 概念の選択/選択解除
- **Ctrl+クリック**: 複数選択
- **折り畳み**: 概念の子要素を表示/非表示

## 6. AI 統合設計

### 6.1 概念抽出プロンプト
```typescript
const conceptExtractionPrompt = `
以下のテキストから主要な概念を箇条書きで抽出してください。
親子関係がある場合はインデントで表現してください。

テキスト: "${userSpeech}"

出力形式:
- メイン概念1
  - サブ概念1-1
  - サブ概念1-2
- メイン概念2
  - サブ概念2-1
`;
```

### 6.2 質問生成プロンプト
```typescript
const questionGenerationPrompt = `
「${selectedConcept}」について、理解を深めるための質問を3つ作成してください。
具体的で答えやすい質問にしてください。
`;
```

## 7. エラーハンドリング

### 7.1 想定されるエラー
- 音声認識の失敗/タイムアウト
- OpenAI API のレート制限
- ネットワークエラー
- APIキーの無効/未設定

### 7.2 対処方針
- ユーザーへの分かりやすいエラーメッセージ表示
- 音声認識は自動再接続
- API エラー時は再試行なし（PoC のため）

## 8. セキュリティ考慮事項

### 8.1 APIキー管理
- ローカルストレージに保存
- サーバーへの送信なし
- 入力時はマスク表示

### 8.2 データプライバシー
- 音声データはブラウザ内処理
- テキストデータのみ OpenAI API へ送信
- セッション終了時にメモリクリア

## 9. 今後の拡張可能性

### 9.1 機能拡張
- データの永続化（バックエンド追加）
- 概念のビジュアル表示（D3.js等）
- 音声コマンドによる操作
- セッション履歴管理

### 9.2 性能改善
- 差分更新による効率化
- キャッシング機構
- バッチ処理の最適化

## 10. 開発スケジュール

### Phase 1: 基盤構築（1週間）
- プロジェクトセットアップ
- 基本コンポーネント実装
- 音声認識統合

### Phase 2: AI統合（1週間）
- OpenAI API 連携
- 概念抽出・質問生成
- UI完成

### Phase 3: 改善・最適化（3-5日）
- バグ修正
- UX改善
- ドキュメント整備